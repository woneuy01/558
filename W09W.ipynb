{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with data in Python\n",
    "\n",
    "The first step in any data project is to get the data ready for analysis. In a traditional business statistics \n",
    "course, the dataset was usually given and ready for analysis from the start. However, this no longer reflects \n",
    "the reality in business and industry: the trend towards big data brought with it an increased \n",
    "demand for professionals with the computational skills to work possibly complex and unstructured data in \n",
    "sophisticated and productive way. It is commonly stated that 80% of a data scientist's job tends to be data \n",
    "preparation, exploratory data analysis (EDA), and visualisation.\n",
    "\n",
    "In data science terminology the process of preparing data is called data wrangling or munging. Common tasks \n",
    "include importing data, merging datasets, identifying and handling errors (data cleaning), dealing with \n",
    "missing values, investigating outliers, transforming variable and creating new ones, etc.\n",
    "\n",
    "In this lesson we explore the basics of how to use [the pandas package](https://pandas.pydata.org) to work \n",
    "efficiently with data in Python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installing pandas \n",
    "\n",
    "If you installed python with Anaconda, you may already have old version of Pandas. But you can update it. If you \n",
    "installed python directly from https://www.python.org, you may not have Pandas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Installing or updating Pandas through Anaconda\n",
    "\n",
    "First, you can check whether you already have Pandas. You can open Anaconda Prompt\n",
    "    <img src=\"http://drive.google.com/uc?export=view&id=1ekWxy7KezMl5YvAN3sR84luHHhQ-_JaK\" width=\"600\">\n",
    "\n",
    "Second, you can type pip list (see Figure below) \n",
    "    <img src=\"http://drive.google.com/uc?export=view&id=1NJXAgraZbSNnjlnsQtu5K_k5ftyPsCOV\" width=\"600\">\n",
    "or \n",
    "    help(\"modules\")\n",
    "to check whether you already have Pandas.\n",
    "\n",
    "Third, you can type conda install pandas to install or update pandas. \n",
    "    <img src=\"http://drive.google.com/uc?export=view&id=1N7E5qEVGIUFWsAt9jjvm6AVoqYjtKZzN\" width=\"600\">\n",
    "\n",
    "After a couple of minutes, you may see the results shown in the following figure \n",
    "    <img src=\"http://drive.google.com/uc?export=view&id=1FkQXuFR-6h0vAwb9i8l58P8MKQED1AVq\" width=\"800\">\n",
    "\n",
    "and you should be able to use pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Installing pandas from the command line using pip \n",
    "\n",
    "If you installed python directly from https://www.python.org, you may not have Pandas. You can install pandas from the command line. \n",
    "\n",
    "First, you can open your command line. If you do not know how to open the \n",
    "command line, you can watch the video on youtube at \n",
    "[here](https://www.youtube.com/watch?v=uE9WgNr3OjM) for Windows and \n",
    "[here](https://www.youtube.com/watch?v=zw7Nd67_aFw) for Mac. \n",
    "\n",
    "Second, you can check whether you alreay have the pandas package by \n",
    "running\n",
    "\n",
    "    pip list \n",
    "    \n",
    "or \n",
    "\n",
    "    help(\"modules\")\n",
    "\n",
    "If you do not install pandas, you can type \n",
    "\n",
    "    pip install pandas\n",
    "    \n",
    "in your command line to install it.  However, if you already installed pandas, you can type \n",
    "\n",
    "    python -m pip install --upgrade pandas\n",
    "    \n",
    "in your command line to update it.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset\n",
    "\n",
    "In this lesson we will use the Credit dataset taken from the Introduction to Statistical Learning texbook by \n",
    "James, Witten, Hastie and Tibshirani with slight modification. You can download this dataset from the course website. \n",
    "The dataset records the average \n",
    "credit card balace at end of the month for customers of a financial \n",
    "services company, as well as other individual characteristics such \n",
    "age, education, gender, marital status, number of cards, and credit \n",
    "rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Importing and viewing data\n",
    "\n",
    "We start by loading the data. First, we need to load the pandas package. \n",
    "Since the dataset is in the csv format, we use the \n",
    "[read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) function to \n",
    "import the file. The package will automatically read the column names \n",
    "and infer the variable types. We assign the data variable to a variable \n",
    "called data, which will store the dataset as an object called a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('credit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also read the data directly from the website. Note that the dataset given in the\n",
    "link http://www-bcf.usc.edu/~gareth/ISL/Credit.csv is slightly different from the data set \n",
    "downloaded from the course website. We will use data instead of data2 later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)    ## you will get a traceback because we already delete the object data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv('http://www-bcf.usc.edu/~gareth/ISL/Credit.csv')\n",
    "print(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pandas DataFrame has some similarities to a spreadsheet. However, \n",
    "unlike a spreadsheet, you are not able to click through it or manually \n",
    "make modifications in the current setup. We do everything through \n",
    "coding. This may initially feel restrictive, but it is ultimately more \n",
    "efficient and scalable to work in this way. Some Python environments \n",
    "such as [Spyder](https://www.spyder-ide.org) have GUIs (graphical \n",
    "user interfaces) for viewing data frames.\n",
    "\n",
    "Two basic methods to have a first view of the data are the head and \n",
    "tail methods. The head method displays the first rows of the data (by \n",
    "default five), while the tail displays the last rows. You can specify \n",
    "the number of rows within the parentheses.\n",
    "\n",
    "Running a cell with only the name of the DataFrame will provide a full \n",
    "view, but pandas limits number of rows that can be shown. See \n",
    "[here](https://stackoverflow.com/questions/19124601/pretty-print-an-entire-pandas-series-dataframe) if \n",
    "you want to change this setting.\n",
    "\n",
    "Note that only the last line of a Jupyter cell will generate an output \n",
    "on the screen. We can use the print function from standard Python \n",
    "library to output multiple variables (see the next section for some \n",
    "examples). However, print does not include the DataFrame table \n",
    "formatting that you can see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('credit.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rows of our DataFrame have a numerical index (in bold above), which \n",
    "is the default behaviour. An important detail, if you are not used to \n",
    "Python or some other programming languages, is that the index starts \n",
    "from zero instead of one. Numerical indexes start from zero in Python. \n",
    "This does not need to be the case in the DataFrame, but pandas follows \n",
    "the Python convention by default.\n",
    "\n",
    "Alternatively, we can specify the DataFrame index (that is, a label for \n",
    "each row), which does not need to be a number. For example, if you have \n",
    "time series data, it can be the date. See the practice section below for \n",
    "another example.\n",
    "\n",
    "In our case we can see that the first column is an observation index, so \n",
    "that we could specify that this is the case when reading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rename Columns\n",
    "data.columns = ['Obs', 'Income', 'Limit', 'Rating', 'Cards', 'Age', \n",
    "                'Education', 'Gender', 'Student', 'Married', 'Ethnicity',\n",
    "                'Balance']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Reading other types of files\n",
    "\n",
    "Pandas has specialised functions for reading other types of input, such \n",
    "as Excel files. You can see a \n",
    "[list](http://pandas.pydata.org/pandas-docs/stable/user_guide/io.html) \n",
    "of available functions here. The pandas \n",
    "[read_table](http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_table.html) \n",
    "function reads data stored as general delimited text \n",
    "files (for example, where the columns are separated by space rather than \n",
    "commas). In practical business situations, you may often need to obtain \n",
    "data from a [relational database](https://en.wikipedia.org/wiki/Relational_database) rather \n",
    "than having to load a flat file \n",
    "stored in your computer. You can read database queries and tables input \n",
    "into a DataFrame by using use the read_sql_table, read_sql_query, or \n",
    "read_sql functions.\n",
    "\n",
    "Our dataset here is simple to work with, but others may require \n",
    "customising the function call. Refer to the documentation for finding \n",
    "the appropriate options for other data that you come across."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data selection\n",
    "\n",
    "There are two ways to select data in pandas: by providing the column \n",
    "and index labels or by providing a numerical index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Selecting a column by label\n",
    "\n",
    "The output will now look different because selecting only one column \n",
    "returns a Series (a specialised object for when there is only one column \n",
    "of data) rather than a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Income'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Income']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Selecting multiple columns by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Income','Education']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Income','Education']].tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Income','Education']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the inner brackets is to indicate that we are passing a list of \n",
    "column names. The example will make this clear, and is a useful template \n",
    "for some of what we will do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=['Income','Education']\n",
    "print(type(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(names)\n",
    "data[names].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Selecting a column by a numerical index\n",
    "\n",
    "The iloc method allows us to select data by numerical indexes. We \n",
    "just have to be careful not be confused by zero indexing. If want \n",
    "the first column then, the index needs to be zero. The following is \n",
    "equivalent to what we did in above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:,0].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Selecting multiple columns by numerical indexes\n",
    "Here, we pass a list of column numbers for indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:,[0, 1, 2, 3, 6]].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_column = [0, 1, 2, 3, 6]\n",
    "data.iloc[:, id_column].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another method is slicing. Suppose that we want to select the data \n",
    "from the 1st to the 6th column. When specifying a range of integer \n",
    "indexes, the last one does not count. This may be initially confusing, \n",
    "but is the standard Python syntax. What the cell below does is to \n",
    "request indexes 0, 1, 2, 3, 4, 5, which correspond to columns 1-6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:,0:6].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_column = range(0,6)\n",
    "data.iloc[:, id_column].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Selecting rows by labels\n",
    "\n",
    "The loc method allows to select rows by the designated index labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[[1,2,5],:]  ## select rows 2, 3, and 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[1:2,:]  ## select rows 2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[1:5,:]  ## select rows 2-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Jointly selecting rows and columns\n",
    "\n",
    "We can combine the previous examples to simultaneously select specific \n",
    "rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[1:5,['Income', 'Education']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[0:2,[0,5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 Mixing labels and numerical indexes\n",
    "\n",
    "As a more advanced concept, a slice of a DataFrame is itself a pandas \n",
    "object (a DataFrame if the slice has multiple columns, or a Series if \n",
    "it has only one). That means that we can chain operations when writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Income', 'Education']].iloc[0:3,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conditional selection\n",
    "\n",
    "Suppose that we want to know the sample average credit card balance \n",
    "only for males. Below, we select the balance column and the rows such \n",
    "that the value of the gender column is male."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Gender'] =='Male'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is called boolean indexing in Python, because it involves the \n",
    "creation of binary variables indicating whether the condition is true \n",
    "of false for each row. The next cell will help you to understand this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['Gender'].head(3))\n",
    "print(data['Gender'].head(3)=='Male')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdata = data.loc[data['Gender'] =='Male', :]\n",
    "subdata.head()\n",
    "subdata['Balance']\n",
    "subdata['Balance'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## another way\n",
    "data.loc[data['Gender'] =='Male','Balance'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also specify multiple conditions. The following selects males \n",
    "with age equal or lower than 30. You can look at this reference for a \n",
    "list of Python comparison operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_selected = (data['Gender']=='Male') & (data['Age']<=30)\n",
    "data.loc[row_selected,'Balance'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[(data['Gender']=='Male') & (data['Age']<=30),'Balance'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Assigning new values to a data selection\n",
    "\n",
    "You may have noted that the age of the second observation is -82. \n",
    "This is an unintentional error in the data. \n",
    "\n",
    "We can use our data selection knowledge to fix this. Below, we joinly \n",
    "select the rows in which the age is negative and the age column. \n",
    "We then replace the values in those locations with the correct label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_age_flag = data['Age'] <= 0\n",
    "row_age_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[row_age_flag,'Age'] = 82\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('credit.csv')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.iloc[1, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[1, 5] = 82\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noted that the gender of the first observation is ' Male'\n",
    "instead of 'Male'. This is an unintentional error in the data. The \n",
    "[unique](http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.unique.html) method in pandas \n",
    "allows us to view all the unique values in a column. In this case, it \n",
    "confirms that all entries are like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Gender'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use our data selection knowledge to fix this. Below, we joinly \n",
    "select the rows in which the gender is \" Male\" and the Gender column. \n",
    "We then replace the values in those locations with the correct label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_gender_flag = data['Gender'] ==' Male'\n",
    "data.loc[row_gender_flag,'Gender']='Male'\n",
    "data['Gender'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Exporting data\n",
    "\n",
    "Once you have made the necessary modications to the dataset, you may \n",
    "want to save it to continue working on it later. More generally, you \n",
    "may wish to save the results of your analysis or export tables so that \n",
    "they insert them in a report or webpage (after formatting). Pandas has \n",
    "methods to export data as \n",
    "[csv](http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html) \n",
    "and [Excel](http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_excel.html) \n",
    "files, [LaTex](http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_latex.html) and \n",
    "[HTML](http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_html.html#pandas.DataFrame.to_html) tables, \n",
    "among [other options](http://pandas.pydata.org/pandas-docs/stable/reference/frame.html).\n",
    "\n",
    "In the following example I export our DataFrame as an Excel file. You \n",
    "can run the cell and try to open the file in Excel to check that it \n",
    "worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## you may need to install the openpyxl package\n",
    "data.to_excel('new_data.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Descriptive Statistics\n",
    "\n",
    "After loading and preparing the data, we can start exploring it with \n",
    "basic descriptive statitistics. The describe method provides a table \n",
    "with basic summary statitics for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.drop(columns='Unnamed: 0')\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data.drop(columns=['Unnamed: 0', 'Income'])\n",
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.describe().round(1)  ## round to 1 decimal place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.describe().round(2)  ## round to 2 decimal places"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also individual functions for a range of summary statistics. \n",
    "Refer to the [pandas documentation](http://pandas.pydata.org/pandas-docs/stable/index.html) for a full list of available \n",
    "functions. As examples, we calculate the means of the dataset and the \n",
    "correlation between income and credit card limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Income','Limit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Income','Limit']].corr().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Data column types\n",
    "\n",
    "When preparing complex datasets for analysis, it is often useful to \n",
    "work with different types of variables (say, numerical or categorical) \n",
    "separately. You can use the dataframe info method to view the list of \n",
    "columns and their variable types, which pandas calls dtypes. The object \n",
    "dtype is the most general type: a column with this dtype will typically \n",
    "contain text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select columns of a particular type, you can do as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_variables = data.select_dtypes(['object'])\n",
    "text_variables.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Other data skills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will cover the basic steps to get started with data wrangling in \n",
    "Python later. Here are some other useful skills that we address in \n",
    "this course later.\n",
    "\n",
    "-  Data transformation and creating new variables.\n",
    "-  Handling missing data and errors.\n",
    "-  Combining and merging datasets.\n",
    "-  Data aggregation and group operations.\n",
    "-  Working with time stamped data.\n",
    "-  Processing text data.\n",
    "-  Extracting data from XML and HTML content.\n",
    "-  Interacting with Web APIs.\n",
    "-  Interacting with databases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "The marketing team at the financial services company that offers the \n",
    "credit card would like to better understand their clients in order \n",
    "to identify high value existing and potential customers to send \n",
    "offers to. Using descriptive statistics, investigate\n",
    "\n",
    "(a) Do gender or ethinicity seem related to the number of cards that \n",
    "a customer owns?\n",
    "\n",
    "(b) Which variables have the highest correlation with monthly credit \n",
    "card balance? Are there any other interesting correlations in the data?\n",
    "\n",
    "The cell below starts the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_ex1 = pd.read_csv('credit.csv')\n",
    "data_ex1.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "The population.xlsx file (downloadable from the course website) contains World Bank data on \n",
    "the total population of countries and regions in 1960 and 2015.\n",
    "\n",
    "(a) Use the appropriate pandas function to import the data and specify the country name as \n",
    "    the index label (the column name is 'Country' in the original file).\n",
    "    \n",
    "(b) Display the first five rows.\n",
    "\n",
    "(c) Display the data for Australia, China, and New Zealand only.\n",
    "\n",
    "(d) Display the population size for all countries with population higher than 100 million \n",
    "    in 2015.\n",
    "\n",
    "(e) Add one new column in the data frame to report the population growth \n",
    "    from 1960 to 2015 for all countries using the following formula:\n",
    "       population growth = (the population size in 2015)/(the population size in 1960)-1\n",
    "    \n",
    "(f) Create a new dataframe, large_population, which contains a copy of the data selected \n",
    "    in (e). Save it as an Excel file. Open it in Excel, do some basic formatting, and \n",
    "    transfer the final table to Word as you may do when writing a report.\n",
    "    \n",
    "The cell below starts the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_ex2 = pd.read_excel('population.xlsx')    ## you may need to install python package xlrd\n",
    "data_ex2.head()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
