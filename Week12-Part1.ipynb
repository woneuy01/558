{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTML and Web Scraping\n",
    "\n",
    "\n",
    "The web provides us with more data than any of us can read and understand, so we often want to work with that information programmatically in order to make sense of it. Sometimes, that data is provided to us by website creators via .csv or comma-separated values files, or through an API (Application Programming Interface). Other times, we need to collect text from the web ourselves.\n",
    "\n",
    "This tutorial will go over how to work with the Requests and Beautiful Soup Python packages in order to make use of data from web pages. The Requests module lets you integrate your Python programs with web services, while the Beautiful Soup module is designed to make screen-scraping get done quickly. Using the Python interactive console and these two libraries, we’ll go through how to collect a web page and work with the textual information available there. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Requests and Beautiful Soup\n",
    "\n",
    "You may already have the libraries \n",
    "[Requests](https://pypi.org/project/requests/2.7.0/) and \n",
    "[Beautiful Soup](https://pypi.org/project/beautifulsoup4/) if you\n",
    "installed Python via anaconda. \n",
    "\n",
    "You can open Anaconda Prompt and type \n",
    "```python\n",
    "conda list\n",
    "``` \n",
    "to view the list of packages and versions installed in active environment.  \n",
    "See [conda cheat sheet](https://docs.conda.io/projects/conda/en/4.6.0/_downloads/52a95608c49671267e40c689e0bc00ca/conda-cheatsheet.pdf) for\n",
    "more details.\n",
    "\n",
    "You can also get into python prompt and type\n",
    "```python\n",
    "help(\"modules\")\n",
    "```\n",
    "to view the list of packages and versions installed in your computer.\n",
    "\n",
    "If you have not installed the python libraries Requests and Beautiful \n",
    "Soup, you can type \n",
    "```python\n",
    "pip install requests beautifulsoup4\n",
    "```\n",
    "to install both python libraries.\n",
    "\n",
    "Now that both Beautiful Soup and Requests are installed, we can move \n",
    "on to understanding how to work with the libraries to scrape websites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting a Web Page with Requests\n",
    "\n",
    "Let's first import the Requests module so that we can collect a sample web page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We’ll assign the URL (below) of the sample web page to the variable url: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.yelp.com/search?find_desc=Restaurants&find_loc=Fullerton%2C+CA&ns=1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can assign the result of a request of that page to the \n",
    "variable page with the request.get() method. We pass the page’s \n",
    "URL (that was assigned to the url variable) to that method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable page is assigned a Response object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Response object above tells us the status_code property in square \n",
    "brackets (in this case 200). This attribute can be called explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned code of 200 tells us that the page downloaded successfully. \n",
    "Codes that begin with the number 2 generally indicate success, while \n",
    "codes that begin with a 4 or 5 indicate that an error occurred. You \n",
    "can read more about HTTP status codes from the [W3C’s Status Code \n",
    "Definitions](https://www.w3.org/Protocols/HTTP/1.1/draft-ietf-http-v11-spec-01#Status-Codes).\n",
    "\n",
    "In order to work with web data, we’re going to want to access the \n",
    "text-based content of web files. We can read the content of the \n",
    "server’s response with page.text (or page.content if we would like \n",
    "to access the response in bytes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also type \n",
    "view-source:https://www.yelp.com/search?find_desc=Restaurants&find_loc=fullerton%2C%20CA\n",
    "in the brower to view source code fo the website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page.text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another example for using requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url2 = \"https://dailytitan.com/2019/03/csuf-baseball-to-open-big-west-play-against-no-17-ucsb/\"\n",
    "page2 = requests.get(url2)\n",
    "page2.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the full text of the page was printed out, with all \n",
    "of its HTML tags. However, it is difficult to read because there is \n",
    "not much spacing.\n",
    "\n",
    "In the next section, we can leverage the Beautiful Soup module to \n",
    "work with this textual data in a more human-friendly manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stepping Through a Page with Beautiful Soup\n",
    "\n",
    "The Beautiful Soup library creates a parse tree from parsed HTML and XML \n",
    "documents (including documents with non-closed tags or tag soup and \n",
    "other malformed markup). This functionality will make the web page text \n",
    "more readable than what we saw coming from the Requests module.\n",
    "\n",
    "To start, we’ll import Beautiful Soup into the Python console:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we’ll run the page.text document through the module to give \n",
    "us a BeautifulSoup object — that is, a parse tree from this parsed \n",
    "page that we’ll get from running Python’s built-in html.parser over \n",
    "the HTML. The constructed object represents the above website document \n",
    "as a nested data structure. This is assigned to the variable soup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show the contents of the page on the terminal, we can print it with \n",
    "the prettify() method in order to turn the Beautiful Soup parse tree \n",
    "into a nicely formatted Unicode string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "This will render each HTML tag on its own line. In the output above, \n",
    "we can see that there is one tag per line and also that the tags are \n",
    "nested because of the tree schema used by Beautiful Soup. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Instances of a Tag\n",
    "\n",
    "We can extract a single tag from a page by using Beautiful Soup’s \n",
    "**find_all** method. This will return all instances of a given tag \n",
    "within a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Running that method on our object returns the full text \n",
    "along with the relevant &lt;p&gt; tags and any tags contained \n",
    "within that requested tag, which here includes the line break \n",
    "tags &lt;br/&gt;. You will notice in the output above that the data is \n",
    "contained in square brackets [ ]. This means it is a Python list \n",
    "data type. \n",
    "\n",
    "Because it is a list, we can call a particular item within \n",
    "it (for example, the third &lt;p&gt; element), and use \n",
    "the **get_text()** method \n",
    "to extract all the text from inside that tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('p')[2].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The output that we receive will be Inexpensive, which is in the \n",
    "third &lt;p&gt; element in this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Below is a completed python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Complete Python Code\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.yelp.com/search?find_desc=Restaurants&find_loc=Fullerton%2C+CA&ns=1\"\n",
    "page = requests.get(url)\n",
    "\n",
    "# page -- <Response [200]>\n",
    "\n",
    "print(\"\\n\", page.status_code)  ## 200\n",
    "\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "print(\"\\n\", soup.prettify())\n",
    "\n",
    "for link in soup.find_all('a'):\n",
    "    print(\"\\n\", link)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
